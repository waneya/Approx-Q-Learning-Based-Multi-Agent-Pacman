# AI Method 2 - Heuristic search algorithms

There are certain features utilised within the approximate Q-learning approach that would require costly search calculations to achieve a true value representation. And so, heuristic functions must be used to approximate values. However this must be done carefully as ill-defined heuristics in this case of the pacman game and our agents could lead to sub-optimal and adverse behaviour.

# Table of Contents
- [Governing Strategy Tree](#governing-strategy-tree)
  * [Motivation](#motivation)
  * [Application](#application)
  * [Trade-offs](#trade-offs)     
     - [Advantages](#advantages)
     - [Disadvantages](#disadvantages)
  * [Future improvements](#future-improvements)

## Governing Strategy Tree  

### Motivation  


[Back to top](#table-of-contents)

### The heuristics utilised or explored

***Maze distance `(getMazeDistance)`:*** 

***Manhattan distance:***

***Manhattan distance:***




[Back to top](#table-of-contents)

### Trade-offs  
#### *Benefits*  


#### *Challenges*

[Back to top](#table-of-contents)

### Future improvements  

[Back to top](#table-of-contents)



[Previous Page](/2_1_approach) | [Next Page](/2_3_approach)