# Approach 2: Heuristic search algorithms

Heuristic search algorithms are those that attempt to estimate the cost of reaching a certain goal, given a partial step towards that goal. In the context of pacman this can be very helpful for two reasons:
**1.** Some search algorithms that provide optimal solutions (e.g. minimum spanning tree) are computationally expensive and unfeasible within the 1sec inter-turn computational time limit for each agent. Heuristic search algorithms can overcome this and still at times provide an equally optimal solution if they are admissible; and
**2.** There are some problems that must be tackled to improve agent performance, which are not directly informed to us by the game, and so, a heuristic is created to find a sufficient method of approaching that problem - and heuristic functions are utilised to contribute to the action decision process of the agents (after appropriate weighting).

There are certain features utilised within our approximate Q-learning approach that require costly search calculations to achieve a true value representation. And so, heuristic functions can act as reasonable proxies to approximate values. However this must be done carefully as ill-defined (i.e. inadmissible) heuristics could lead to sub-optimal and adverse agent actions taken.

1. Dead-ends
2. Distance to enemy when not visible
3. Problem:
Top and bottom 
5. Returning home when timer exceeds a certain point, or 1/3 of nearby food

### 'Dead-end' heuristic and 7-step iterative deepening search

To tackle the issue of dead-ends, and our agents being trapped by them in enemy territory, first we decided on a heuristic for solving this problem, which was how many possible actions could an agent take at a given state (i.e. 4 - # surround walls; not including 'stop' action). This combined with an iterative deepening search allowed our agents to reasonably avoid dead ends when escaping enemy ghosts.

A challenge of this approach remained in terms of the computational expense of calculating this at every turn. We found that our team failed the time limit when searches were completed in anticipation of 8+ steps, and so we settled for our agents to account for dead-ends within a 7-step understanding.

***Maze distance:*** 

***Manhattan distance:***

***Noisy distance:***

The problem: when should an agent return home after eating food? A heuristic to minimise chance of getting eaten but also maximise score over the entire game

The mechanism: sqrt(height*width) map < maze distance to food 

Second mechanism: If there is a lot of food nearby (i.e. connected by 1 square), go back home after eating half of total food

### Challenges experienced


### Possible improvements  



[Previous Page](/2_1_approach) | [Next Page](/2_3_approach)